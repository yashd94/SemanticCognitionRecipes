{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from __future__ import print_function\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.functional import sigmoid, relu\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('featurized_condensed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['Unnamed: 0', 'Unnamed: 10', 'Ingredients'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.set_index('ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuisines = list(set(df['Cuisine']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_cuisines = {}\n",
    "counter = 0\n",
    "for i in cuisines:\n",
    "    length = np.zeros(len(cuisines))\n",
    "    length[counter] = 1\n",
    "    length = length.tolist()\n",
    "    counter += 1\n",
    "    binary_cuisines[i] = length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lists = {}\n",
    "for i in df.iterrows():\n",
    "    i[1][0] = binary_cuisines[i[1][0]]\n",
    "    lists[i[0]] = i[1][0]+i[1][1:].get_values().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "['thai' 'korean' 'japanese' 'cajun_creole' 'italian' 'indian' 'vietnamese'\n",
      " 'jamaican' 'british' 'mexican' 'southern_us' 'chinese' 'greek' 'filipino'\n",
      " 'moroccan' 'brazilian' 'irish' 'french' 'spanish' 'russian']\n",
      "6\n",
      "['Vegeterian (Y/N)' 'Vegan (Y/N)' 'Dessert (Y/N)' 'Spicy (Y/N)'\n",
      " 'Drink (Y/N)' 'Alcohol (Y/N)']\n",
      "395\n",
      "Index(['paprika', 'quail eggs', 'sweet chili sauce', 'half & half',\n",
      "       'allspice berries', 'carrots', 'peppercorns', 'cardamom',\n",
      "       'vanilla ice cream', 'red chili',\n",
      "       ...\n",
      "       'paneer', 'cheese', 'onion powder', 'cauliflower', 'lemon juice',\n",
      "       'vinegar', 'tumeric', 'back bacon rashers', 'plum tomatoes', 'beets'],\n",
      "      dtype='object', length=395)\n"
     ]
    }
   ],
   "source": [
    "ncuisines = len(df['Cuisine'].unique())\n",
    "print(ncuisines)\n",
    "print(df['Cuisine'].unique())\n",
    "nattributes = len(df.columns[1:7])\n",
    "print(nattributes)\n",
    "print(np.array(df.columns[1:7]))\n",
    "ningredients = len(df.columns[7:])\n",
    "print(ningredients)\n",
    "print(df.columns[7:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_df = pd.DataFrame(lists)\n",
    "input_pats = binary_df.iloc[:,:ncuisines+nattributes]\n",
    "input_pats = torch.tensor(np.array(input_pats),dtype=torch.float)\n",
    "output_pats = binary_df.iloc[:,ncuisines+nattributes:]\n",
    "output_pats = torch.tensor(np.array(output_pats),dtype=torch.float)\n",
    "N = input_pats.shape[0] # number of training patterns\n",
    "input_v = input_pats[0,:].numpy().astype('bool')\n",
    "output_v = output_pats[0,:].numpy().astype('bool')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, rep_size, hidden_size):\n",
    "        super(Net, self).__init__()\n",
    "        # Input\n",
    "        #  rep_size : number of hidden units in \"Representation Layer\"\n",
    "        #  hidden_Size : number of hidden units in \"Hidden Layer\"\n",
    "        #\n",
    "        # TODO : YOUR CODE GOES HERE    \n",
    "        \n",
    "        self.i2r = nn.Linear(ncuisines+nattributes, rep_size)\n",
    "        self.r2h = nn.Linear(rep_size, hidden_size)\n",
    "        self.h2o = nn.Linear(hidden_size, ningredients)\n",
    "        #raise Exception('Replace with your code.')\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Defines forward pass for the network on input patterns x\n",
    "        #\n",
    "        # Input can take these two forms:\n",
    "        #\n",
    "        #   x: [nobj+nrel 1D Tensor], which is a single input pattern as a 1D tensor\n",
    "        #      (containing both object and relation 1-hot identifier) (batch size is B=1)\n",
    "        #   OR\n",
    "        #   x : [B x (nobj+nrel) Tensor], which is a batch of B input patterns (one for each row)\n",
    "        #\n",
    "        # Output\n",
    "        #   output [B x nattribute Tensor], which is the output pattern for each input pattern B on the Attribute Layer\n",
    "        #   hidden [B x hidden_size Tensor], which are activations in the Hidden Layer\n",
    "        #   rep [B x rep_size Tensor], which are the activations in the Representation LAyer\n",
    "        x = x.view(-1,ncuisines+nattributes) # reshape as size [B x (nobj+nrel) Tensor] if B=1\n",
    "        x_item = x[:,:ncuisines+nattributes] # input to Item Layer [B x nobj Tensor]\n",
    "#         print(\"x item shape \"+ str(x_item.shape))\n",
    "        #x_rel = x[:,ncuisines:] # input to Relation Layer [B x nrel Tensor]\n",
    "        # TODO : YOUR CODE GOES HERE\n",
    "        \n",
    "        rep = self.i2r(x_item)\n",
    "        rep = relu(rep)\n",
    "        #combined = torch.cat((rep, x_rel),1)\n",
    "        hidden = self.r2h(rep)\n",
    "        hidden = relu(hidden)\n",
    "        output = self.h2o(hidden)\n",
    "        output = sigmoid(output)\n",
    "        #raise Exception('Replace with your code.')\n",
    "\n",
    "        return output, hidden, rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(mynet,epoch_count,nepochs_additional=5000):\n",
    "    # Input\n",
    "    #  mynet : Net class object\n",
    "    #  epoch_count : (scalar) how many epochs have been completed so far\n",
    "    #  nepochs_additional : (scalar) how many more epochs we want to run\n",
    "    mynet.train()\n",
    "    for e in range(nepochs_additional): # for each epoch\n",
    "        error_epoch = 0.\n",
    "        perm = np.random.permutation(N)\n",
    "        for p in perm: # iterate through input patterns in random order\n",
    "            mynet.zero_grad() # reset gradient\n",
    "            output, hidden, rep = mynet(input_pats[p,:]) # forward pass\n",
    "            target = output_pats[p,:] \n",
    "            loss = criterion(output, target) # compute loss\n",
    "            loss.backward() # compute gradient \n",
    "            optimizer.step() # update network parameters\n",
    "            error_epoch += loss.item()\n",
    "        error_epoch = error_epoch / float(N)        \n",
    "        if e % 50 == 0:\n",
    "            print('epoch ' + str(epoch_count+e) + ' loss ' + str(round(error_epoch,3)))\n",
    "    return epoch_count + nepochs_additional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rep(net):\n",
    "    # Extract the hidden activations on the Representation Layer for each item\n",
    "    # \n",
    "    # Input\n",
    "    #  net : Net class object\n",
    "    #\n",
    "    # Output\n",
    "    #  rep : [nitem x rep_size numpy array], where each row is an item\n",
    "    input_clean = torch.zeros(nobj,nobj+nrel)\n",
    "    for idx,name in enumerate(names_items):\n",
    "        input_clean[idx,idx] = 1. # 1-hot encoding of each object (while Relation Layer doesn't matter)\n",
    "    output, hidden, rep = mynet(input_clean)\n",
    "    return rep.detach().numpy()\n",
    "\n",
    "def plot_rep(rep1,rep2,rep3,names):\n",
    "    #  Compares Representation Layer activations of Items at three different times points in learning (rep1, rep2, rep3)\n",
    "    #  using bar graphs\n",
    "    # \n",
    "    #  Each rep1, rep2, rep3 is a [nitem x rep_size numpy array]\n",
    "    #  names : [nitem list] of item names\n",
    "    #\n",
    "    nepochs_list = [nepochs_phase1,nepochs_phase2,nepochs_phase3]\n",
    "    nrows = nobj\n",
    "    R = np.dstack((rep1,rep2,rep3))    \n",
    "    mx = R.max()\n",
    "    mn = R.min()\n",
    "    depth = R.shape[2]\n",
    "    count = 1\n",
    "    plt.figure(1,figsize=(4.2,8.4))\n",
    "    for i in range(nrows):\n",
    "        for d in range(R.shape[2]):\n",
    "            plt.subplot(nrows, depth, count)\n",
    "            rep = R[i,:,d]\n",
    "            plt.bar(range(rep.size),rep)\n",
    "            plt.ylim([mn,mx])\n",
    "            plt.xticks([])\n",
    "            plt.yticks([])        \n",
    "            if d==0:\n",
    "                plt.ylabel(names[i])\n",
    "            if i==0:\n",
    "                plt.title(\"epoch \" + str(nepochs_list[d]))\n",
    "            count += 1\n",
    "    plt.show()\n",
    "\n",
    "def plot_dendo(rep1,rep2,rep3,names):\n",
    "    #  Compares Representation Layer activations of Items at three different times points in learning (rep1, rep2, rep3)\n",
    "    #  using hierarchical clustering\n",
    "    # \n",
    "    #  Each rep1, rep2, rep3 is a [nitem x rep_size numpy array]\n",
    "    #  names : [nitem list] of item names\n",
    "    #\n",
    "    nepochs_list = [nepochs_phase1,nepochs_phase2,nepochs_phase3]\n",
    "    linked1 = linkage(rep1,'single')\n",
    "    linked2 = linkage(rep2,'single')\n",
    "    linked3 = linkage(rep3,'single')\n",
    "    mx = np.dstack((linked1[:,2],linked2[:,2],linked3[:,2])).max()+0.1    \n",
    "    plt.figure(2,figsize=(7,12))\n",
    "    plt.subplot(3,1,1)    \n",
    "    dendrogram(linked1, labels=names, color_threshold=0)\n",
    "    plt.ylim([0,mx])\n",
    "    plt.title('Hierarchical clustering; ' + \"epoch \" + str(nepochs_list[0]))\n",
    "    plt.ylabel('Euclidean distance')\n",
    "    plt.subplot(3,1,2)\n",
    "    plt.title(\"epoch \" + str(nepochs_list[1]))\n",
    "    dendrogram(linked2, labels=names, color_threshold=0)\n",
    "    plt.ylim([0,mx])\n",
    "    plt.subplot(3,1,3)\n",
    "    plt.title(\"epoch \" + str(nepochs_list[2]))\n",
    "    dendrogram(linked3, labels=names, color_threshold=0)\n",
    "    plt.ylim([0,mx])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py:1006: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "input and target shapes do not match: input [1 x 395], target [73] at /Users/soumith/miniconda2/conda-bld/pytorch_1532623076075/work/aten/src/THNN/generic/MSECriterion.c:12",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-782847b03682>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mnepochs_phase3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2500\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mepoch_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mepoch_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmynet\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepoch_count\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnepochs_additional\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnepochs_phase1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mrep1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_rep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmynet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mepoch_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmynet\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepoch_count\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnepochs_additional\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnepochs_phase2\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mnepochs_phase1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-42301e31da74>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(mynet, epoch_count, nepochs_additional)\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmynet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_pats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_pats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# compute loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# compute gradient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# update network parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 421\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mmse_loss\u001b[0;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   1714\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1715\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1716\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_pointwise_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1717\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36m_pointwise_loss\u001b[0;34m(lambd, lambd_optimized, input, target, reduction)\u001b[0m\n\u001b[1;32m   1672\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreduction\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'elementwise_mean'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1673\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1674\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlambd_optimized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: input and target shapes do not match: input [1 x 395], target [73] at /Users/soumith/miniconda2/conda-bld/pytorch_1532623076075/work/aten/src/THNN/generic/MSECriterion.c:12"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.1\n",
    "criterion = nn.MSELoss() # mean squared error loss function\n",
    "mynet = Net(rep_size=8,hidden_size=15)\n",
    "optimizer = torch.optim.SGD(mynet.parameters(), lr=learning_rate) # stochastic gradient descent\n",
    "\n",
    "nepochs_phase1 = 500\n",
    "nepochs_phase2 = 1000\n",
    "nepochs_phase3 = 2500\n",
    "epoch_count = 0\n",
    "epoch_count = train(mynet,epoch_count,nepochs_additional=nepochs_phase1)\n",
    "rep1 = get_rep(mynet)\n",
    "epoch_count = train(mynet,epoch_count,nepochs_additional=nepochs_phase2-nepochs_phase1)\n",
    "rep2 = get_rep(mynet)\n",
    "epoch_count = train(mynet,epoch_count,nepochs_additional=nepochs_phase3-nepochs_phase2)\n",
    "rep3 = get_rep(mynet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_rep(rep1,rep2,rep3,names_items)\n",
    "plot_dendo(rep1,rep2,rep3,names_items)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
